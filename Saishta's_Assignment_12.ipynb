{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNH27Vh5DFu9X32A67kNj/A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sai1519/My-projects-and-programs/blob/Machine-Learning/Saishta's_Assignment_12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyi9m1xYtuy-"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries.\n",
        "import numpy as np\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the environment.\n",
        "num_states = 6\n",
        "num_actions = 4\n",
        "\n",
        "# Defining the reward matrix.\n",
        "R = np.array([\n",
        "    [-1,-1,-1,-1,0,-1],\n",
        "    [-1,-1,-1,0,-1,100],\n",
        "    [-1,-1,-1,0,-1,-1],\n",
        "    [-1,0,0,-1,0,-1],\n",
        "    [0,-1,-1,0,-1,100],\n",
        "    [-1,0,-1,-1,0,100]\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "rTrgo4YeuX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing Q table with zeros.\n",
        "Q = np.zeros([num_states, num_actions])"
      ],
      "metadata": {
        "id": "7eLoWkXavSEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the hyperparameters.\n",
        "learning_rate =0.8\n",
        "discount_factor = 0.95\n",
        "exploration_prob =0.2\n",
        "num_episodes = 1000"
      ],
      "metadata": {
        "id": "nd42_coqvjJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying Q learning Algorithms.\n",
        "for episode in range(num_episodes):\n",
        "  state = random.randint(0,num_states -1)\n",
        "\n",
        "  while state !=5:\n",
        "    if random.uniform(0,1) < exploration_prob:\n",
        "      action = random.randint(0, num_actions -1)\n",
        "    else:\n",
        "      action = np.argmax(Q[state, :])\n",
        "\n",
        "    next_state = action\n",
        "    reward = R[state,action]\n",
        "\n",
        "    Q[state, action] = Q[state,action] + learning_rate * (reward + discount_factor * np.max(Q[next_state, :])- Q[state, action])\n",
        "    state = next_state"
      ],
      "metadata": {
        "id": "6-uEpIWnv02D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the optimal policy.\n",
        "optimal_policy = np.argmax(Q, axis =1)\n",
        "print(\"Optimal Policy: \", optimal_policy)"
      ],
      "metadata": {
        "id": "kszKuvvBxM3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the business benefits.\n",
        "optimal_path_length = np.sum(optimal_policy !=5)\n",
        "fuel_cost_savings =15 * optimal_path_length / num_states\n",
        "print(\"Fuel Cost Savings: \", fuel_cost_savings, \"%\")"
      ],
      "metadata": {
        "id": "S2dUwotqxe8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QUI5qih6x6kl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}